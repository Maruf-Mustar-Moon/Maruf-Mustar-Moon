{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "11AVN7jJwTcrklLHJUgvN9jTF2rdMgT-H",
      "authorship_tag": "ABX9TyPyFqkP8RLErpqvUhdnIxSR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruf-Mustar-Moon/Maruf-Mustar-Moon/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzXr5zsOc3lT"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_zVTq-tdT2D"
      },
      "source": [
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import glob \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtcwXU9jdYEJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6vOUr81iaZj"
      },
      "source": [
        "SAVEE = \"/content/drive/MyDrive/Colab Notebooks/SUBESCO/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFtjKb_1imUd"
      },
      "source": [
        "dir_list = os.listdir(SAVEE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MXIPoItiyky"
      },
      "source": [
        "dir_list[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHCEMv2WtMsG"
      },
      "source": [
        "dir_list = os.listdir(SAVEE)\n",
        "path = []\n",
        "emotion = []\n",
        "\n",
        "for i in dir_list:\n",
        "  \n",
        "   \n",
        "        if i[0] == 'F' and i[-11:-6] == 'ANGRY':\n",
        "            emotion.append('female_angry')\n",
        "        elif i[0] == 'F' and i[-13:-6] == 'DISGUST':\n",
        "            emotion.append('female_disgust')\n",
        "        elif i[0] == 'F' and i[-10:-6] == 'FEAR':\n",
        "            emotion.append('female_fear')\n",
        "        elif i[0] == 'F' and i[-11:-6] == 'HAPPY':\n",
        "            emotion.append('female_happy')\n",
        "        elif i[0] == 'F' and i[-13:-6] == 'NEUTRAL':\n",
        "            emotion.append('female_neutral')                                \n",
        "        elif i[0] == 'F' and i[-14:-6] == 'SURPRISE':\n",
        "            emotion.append('female_surprise')               \n",
        "        elif i[0] == 'F' and i[-9:-6] == 'SAD':\n",
        "            emotion.append('female_sad')\n",
        "        elif i[0] == 'M' and i[-11:-6] == 'ANGRY':\n",
        "            emotion.append('male_angry')\n",
        "        elif i[0] == 'M' and i[-13:-6] == 'DISGUST':\n",
        "            emotion.append('male_disgust')\n",
        "        elif i[0] == 'M' and i[-10:-6] == 'FEAR':\n",
        "            emotion.append('male_fear')\n",
        "        elif i[0] == 'M' and i[-11:-6] == 'HAPPY':\n",
        "            emotion.append('male_happy')\n",
        "        elif i[0] == 'M' and i[-13:-6] == 'NEUTRAL':\n",
        "            emotion.append('male_neutral')                                \n",
        "        elif i[0] == 'M' and i[-14:-6] == 'SURPRISE':\n",
        "            emotion.append('male_surprise')               \n",
        "        elif i[0] == 'M' and i[-9:-6] == 'SAD':\n",
        "            emotion.append('male_sad')\n",
        "        \n",
        "        else:\n",
        "            emotion.append('male_error') \n",
        "        path.append(SAVEE + i)\n",
        "\n",
        "SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
        "SAVEE_df['source'] = 'SAVEE'\n",
        "SAVEE_df = pd.concat([SAVEE_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
        "SAVEE_df.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZa8-Nfim3CD"
      },
      "source": [
        "dir_list = os.listdir(SAVEE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz6ZMWGfl2l-"
      },
      "source": [
        "# use the well known Librosa library for this task \n",
        "fname = SAVEE + 'M_08_PRASUN_S_1_SURPRISE_1.wav' \n",
        "data, sampling_rate = librosa.load(fname)\n",
        "plt.figure(figsize=(15, 5))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)\n",
        "\n",
        "# Lets play the audio \n",
        "ipd.Audio(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b50bqSrhnvBO"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import os\n",
        "import IPython.display as ipd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkBvqvMso969"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/SUBESCO/F_01_OISHI_S_10_ANGRY_1.wav\"\n",
        "X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \n",
        "mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "\n",
        "# audio wave\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.subplot(3,1,1)\n",
        "librosa.display.waveplot(X, sr=sample_rate)\n",
        "plt.title('Audio sampled at 44100 hrz')\n",
        "\n",
        "# MFCC\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.subplot(3,1,1)\n",
        "librosa.display.specshow(mfcc, x_axis='time')\n",
        "plt.ylabel('MFCC')\n",
        "plt.colorbar()\n",
        "\n",
        "ipd.Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giQ2NAjQ0dbh"
      },
      "source": [
        "df = pd.concat([SAVEE_df], axis = 0)\n",
        "print(df.labels.value_counts())\n",
        "df.head()\n",
        "df.to_csv(\"Data_path.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb2pf9gRpV9e"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/SUBESCO/M_10_EVAN_S_10_ANGRY_1.wav\"\n",
        "X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \n",
        "mfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n",
        "\n",
        "# audio wave\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.subplot(3,1,1)\n",
        "librosa.display.waveplot(X, sr=sample_rate)\n",
        "plt.title('Audio sampled at 44100 hrz')\n",
        "\n",
        "# MFCC\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.subplot(3,1,1)\n",
        "librosa.display.specshow(mfcc, x_axis='time')\n",
        "plt.ylabel('MFCC')\n",
        "plt.colorbar()\n",
        "\n",
        "ipd.Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JseNfgb3rvxK"
      },
      "source": [
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Other  \n",
        "import librosa\n",
        "import librosa.display\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import glob \n",
        "import os\n",
        "import pickle\n",
        "import IPython.display as ipd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WOfAaX42MM0"
      },
      "source": [
        "ref = pd.read_csv(\"Data_path.csv\")\n",
        "ref.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXuZBq5B2W-7"
      },
      "source": [
        "df = pd.DataFrame(columns=['feature'])\n",
        "\n",
        "\n",
        "counter=0\n",
        "for index,path in enumerate(ref.path):\n",
        "    X, sample_rate = librosa.load(path\n",
        "                                  , res_type='kaiser_fast'\n",
        "                                  ,duration=2.5\n",
        "                                  ,sr=44100\n",
        "                                  ,offset=0.5\n",
        "                                 )\n",
        "    sample_rate = np.array(sample_rate)\n",
        "    \n",
        "    \n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
        "                                        sr=sample_rate, \n",
        "                                        n_mfcc=13),\n",
        "                    axis=0)\n",
        "    df.loc[counter] = [mfccs]\n",
        "    counter=counter+1   \n",
        "\n",
        "\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhHdvlv8_0bX"
      },
      "source": [
        "df = pd.concat([ref,pd.DataFrame(df['feature'].values.tolist())],axis=1)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjftYmVN_5lf"
      },
      "source": [
        "df=df.fillna(0)\n",
        "print(df.shape)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93RAFAh6ASB1"
      },
      "source": [
        "df=df.fillna(0)\n",
        "print(df.shape)\n",
        "df[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCBKa-8iAsDl"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n",
        "                                                    , df.labels\n",
        "                                                    , test_size=0.25\n",
        "                                                    , shuffle=True\n",
        "                                                    , random_state=42\n",
        "                                                   )\n",
        "\n",
        "\n",
        "X_train[150:160]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQTZCd6YAzRq"
      },
      "source": [
        "\n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "\n",
        "\n",
        "X_train[150:160]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnmrn_jgBBY_"
      },
      "source": [
        "max_data = np.max(X_train)\n",
        "min_data = np.min(X_train)\n",
        "X_train = (X_train-min_data)/(max_data-min_data+1e-6)\n",
        "X_train =  X_train-0.5\n",
        "\n",
        "max_data = np.max(X_test)\n",
        "min_data = np.min(X_test)\n",
        "X_test = (X_test-min_data)/(max_data-min_data+1e-6)\n",
        "X_test =  X_test-0.5\n",
        "\n",
        "X_train[150:160]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r666k7tBF7D"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(lb.classes_)\n",
        "#print(y_train[0:10])\n",
        "#print(y_test[0:10])\n",
        "\n",
        "# Pickel the lb object for future use \n",
        "filename = 'labels'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(lb,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soU467WJBKt1"
      },
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9gKFaPIH9yR"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGlxo_s0CHfL"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(256, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(14)) # Target class number\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjgI7PdcIbA7"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26GNYUlqGM7o"
      },
      "source": [
        "# Save model and weights\n",
        "model_name = 'Emotion_Model.h5'\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Save model and weights at %s ' % model_path)\n",
        "\n",
        "# Save the model to disk\n",
        "model_json = model.to_json()\n",
        "with open(\"model_json.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ZAaDuqGS83"
      },
      "source": [
        "# loading json and model architecture \n",
        "json_file = open('model_json.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"saved_models/Emotion_Model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# Keras optimiser\n",
        "opt = tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.00001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
        "    name='RMSprop'\n",
        ")\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}